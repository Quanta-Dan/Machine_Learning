{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import model_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_count =2\n",
    "parameter_count = exponential_count*2+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a model or creat a new one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True\n",
    "model_path ='models/2024-01-08_16-14-55_2exp_params_205_points_50/model.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crpdn\\AppData\\Local\\Temp\\ipykernel_18052\\431649043.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv('measurements/C_4_1000_20231213_14_15_50.csv', sep=', ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ch1(mA)</th>\n",
       "      <th>Ch2(mA)</th>\n",
       "      <th>Ch3(mA)</th>\n",
       "      <th>Ch4(mA)</th>\n",
       "      <th>Ch5(mA)</th>\n",
       "      <th>Ch6(mA)</th>\n",
       "      <th>Ch7(mA)</th>\n",
       "      <th>Ch8(mA)</th>\n",
       "      <th>Ch9(mA)</th>\n",
       "      <th>Ch10(mA)</th>\n",
       "      <th>...</th>\n",
       "      <th>Ch14(mA)</th>\n",
       "      <th>Ch15(mA)</th>\n",
       "      <th>Ch16(mA)</th>\n",
       "      <th>Channel state</th>\n",
       "      <th>On time</th>\n",
       "      <th>Off time</th>\n",
       "      <th>Pulse number</th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Time</th>\n",
       "      <th>Probeflag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03421</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000000000000</td>\n",
       "      <td>75</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1000</td>\n",
       "      <td>0.087664</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000000000000</td>\n",
       "      <td>75</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1/1000</td>\n",
       "      <td>0.182584</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000000000000</td>\n",
       "      <td>75</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1/1000</td>\n",
       "      <td>0.283189</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000000000000</td>\n",
       "      <td>75</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>1/1000</td>\n",
       "      <td>0.376060</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000000000000</td>\n",
       "      <td>75</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>1/1000</td>\n",
       "      <td>0.469858</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ch1(mA)  Ch2(mA)  Ch3(mA)  Ch4(mA)  Ch5(mA)  Ch6(mA)  Ch7(mA)  Ch8(mA)  \\\n",
       "0        0        0        0  0.03421        0        0        0        0   \n",
       "1        0        0        0  0.04888        0        0        0        0   \n",
       "2        0        0        0  0.06354        0        0        0        0   \n",
       "3        0        0        0  0.08309        0        0        0        0   \n",
       "4        0        0        0  0.09775        0        0        0        0   \n",
       "\n",
       "   Ch9(mA)  Ch10(mA)  ...  Ch14(mA)  Ch15(mA)  Ch16(mA)  Channel state  \\\n",
       "0        0         0  ...         0         0         0  1000000000000   \n",
       "1        0         0  ...         0         0         0  1000000000000   \n",
       "2        0         0  ...         0         0         0  1000000000000   \n",
       "3        0         0  ...         0         0         0  1000000000000   \n",
       "4        0         0  ...         0         0         0  1000000000000   \n",
       "\n",
       "   On time  Off time  Pulse number  Pattern      Time  Probeflag  \n",
       "0       75        22             1   1/1000  0.087664      False  \n",
       "1       75        22             2   1/1000  0.182584      False  \n",
       "2       75        22             3   1/1000  0.283189      False  \n",
       "3       75        22             4   1/1000  0.376060      False  \n",
       "4       75        22             5   1/1000  0.469858      False  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('measurements/C_4_1000_20231213_14_15_50.csv', sep=', ')\n",
    "# df = pd.read_csv('measurements/E_4_20ms_20231103_14_55_46.csv', sep=', ')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_points = 50\n",
    "cutoff_current_min = 0\n",
    "must_be_growth = False\n",
    "must_be_decay = False\n",
    "min_gradient =0\n",
    "max_final_gradient = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_completed = []\n",
    "predicted_param_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss function for the specified task.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Ground truth values, of shape (batch_size, 2, N).\n",
    "    - y_pred: Predicted values, of shape (batch_size, 7,N).\n",
    "\n",
    "    Returns:\n",
    "    - loss: Scalar value representing the mean loss over the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract x and y values from y_true\n",
    "    x_values = y_true[:,:,0]  # Shape: (batch_size, N)\n",
    "    y_values = y_true[:,:,1]  # Shape: (batch_size, N)\n",
    "    \n",
    "    function_values = tf.zeros_like(x_values)\n",
    "    for i in range(int((y_pred.shape[2]-1)/2)):\n",
    "        temp_val= y_pred[:, :,i]*i * K.exp(-(x_values) * y_pred[:, :,i+1]*i)\n",
    "        function_values = function_values+ temp_val\n",
    "    function_values = function_values+y_pred[:,:,-1]\n",
    "    \n",
    "    # square absolute error\n",
    "    diff = (y_values -function_values) \n",
    "    squared_diff = tf.math.square(diff)\n",
    "    mse = tf.math.reduce_sum(squared_diff, axis=-1)\n",
    "\n",
    "\n",
    "    # diff = function_values - y_values\n",
    "    # # print(diff)\n",
    "    # # Take the square of the differences\n",
    "    # squared_diff = K.square(diff)\n",
    "\n",
    "    # slope_comparison = 0.0\n",
    "    # for i in range(y_true.shape[2]-1):\n",
    "    #     x_diff = x_values[:,i+1]-x_values[:,i]  \n",
    "    #     function_slope = (function_values[:,i+1]-function_values[:,i])/x_diff \n",
    "    #     true_slope= (y_values[:,i+1]-y_values[:,i])/x_diff\n",
    "    #     slope_comparison += tf.math.square(true_slope- function_slope)      \n",
    "\n",
    "    # square relative error\n",
    "    # diff = (y_values -function_values) / (y_values+0.0001) #K.maximum(y_values, y_values+0.00001)\n",
    "    # squared_diff = tf.math.square(diff)\n",
    "    # mse = tf.math.reduce_sum(squared_diff, axis=-1)\n",
    "\n",
    "    loss = mse #+ slope_comparison\n",
    "    # loss = K.mean(squared_diff, axis=-1)\n",
    "    return loss\n",
    " \n",
    "\n",
    "def create_nn():\n",
    "    global X_train, points\n",
    "    # Input layer, the number of input nodes is governed by X_data.shape[1]\n",
    "    # X_data.shape[1] is the number of columns in X_data\n",
    "    inputs = keras.Input(shape=(X_train.shape[1],), name='input')\n",
    "    \n",
    "    # Dense layers \n",
    "    #layers_norm = keras.layers.BatchNormalization()(inputs)\n",
    "    layers_dense = keras.layers.Dense(10, 'linear')(inputs)\n",
    "    layers_dense2 = keras.layers.Dense(10, 'linear')(layers_dense)\n",
    "    # layers_dense3 = keras.layers.Dense(20, 'linear')(layers_dense2)\n",
    "    # layers_dense4 = keras.layers.Dense(20, 'linear')(layers_dense3)\n",
    "    # Parameter layer\n",
    "    # layers_norm = keras.layers.LayerNormalization()(layers_dense2)\n",
    "    parameters = keras.layers.Dense(parameter_count)(layers_dense2)\n",
    "    # Expand parameters to have same shape as y_true\n",
    "    expanded_parameters = keras.layers.RepeatVector(points)(parameters)\n",
    "\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=expanded_parameters, name=\"current_function_prediction\")\n",
    "\n",
    "\n",
    "\n",
    "def compile_model(model):\n",
    "    sgd = keras.optimizers.RMSprop(clipnorm=5)\n",
    "    model.compile(optimizer=sgd, #'adam'\n",
    "                  loss=custom_loss)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "earlystopper = keras.callbacks.EarlyStopping(monitor=\"loss\",baseline = 1, patience=number_of_epochs,restore_best_weights=True)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', \n",
    "                              factor=0.8, \n",
    "                              patience=5, \n",
    "                              min_lr=1e-6)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "def plot_history(history, metrics, y_lim):\n",
    "    \"\"\"\n",
    "    Plot the training history\n",
    "\n",
    "    Args:\n",
    "        history (keras History object that is returned by model.fit())\n",
    "        metrics (str, list): Metric or a list of metrics to plot\n",
    "    \"\"\"\n",
    "    history_df = pd.DataFrame.from_dict(history.history)\n",
    "    sns.lineplot(data=history_df[metrics])\n",
    "    if y_lim !=0:\n",
    "        plt.ylim(0,y_lim)\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"metric\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_nn()\n\u001b[0;32m     28\u001b[0m compile_model(model)\n\u001b[1;32m---> 30\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train,\n\u001b[0;32m     31\u001b[0m                 batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     32\u001b[0m                 epochs\u001b[38;5;241m=\u001b[39mnumber_of_epochs,\n\u001b[0;32m     33\u001b[0m                 \u001b[38;5;66;03m# validation_data = (X_val,y_val),\u001b[39;00m\n\u001b[0;32m     34\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39m[earlystopper\n\u001b[0;32m     35\u001b[0m                            ,reduce_lr\n\u001b[0;32m     36\u001b[0m                            ],\n\u001b[0;32m     37\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     38\u001b[0m history_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(history\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[0;32m     39\u001b[0m final_loss \u001b[38;5;241m=\u001b[39m history_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\crpdn\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\crpdn\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1795\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1793\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():\n\u001b[1;32m-> 1795\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m   1796\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[1;32mc:\\Users\\crpdn\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:2723\u001b[0m, in \u001b[0;36mModel.reset_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2704\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the state of all the metrics in the model.\u001b[39;00m\n\u001b[0;32m   2705\u001b[0m \n\u001b[0;32m   2706\u001b[0m \u001b[38;5;124;03mExamples:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2720\u001b[0m \n\u001b[0;32m   2721\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics:\n\u001b[1;32m-> 2723\u001b[0m     m\u001b[38;5;241m.\u001b[39mreset_state()\n",
      "File \u001b[1;32mc:\\Users\\crpdn\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py:265\u001b[0m, in \u001b[0;36mMetric.reset_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_states()\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 265\u001b[0m     backend\u001b[38;5;241m.\u001b[39mbatch_set_value([(v, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables])\n",
      "File \u001b[1;32mc:\\Users\\crpdn\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\crpdn\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\crpdn\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:4311\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   4309\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, value \u001b[38;5;129;01min\u001b[39;00m tuples:\n\u001b[0;32m   4310\u001b[0m         value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(value, dtype\u001b[38;5;241m=\u001b[39mdtype_numpy(x))\n\u001b[1;32m-> 4311\u001b[0m         _assign_value_to_variable(x, value)\n\u001b[0;32m   4312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4313\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_graph()\u001b[38;5;241m.\u001b[39mas_default():\n",
      "File \u001b[1;32mc:\\Users\\crpdn\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:4359\u001b[0m, in \u001b[0;36m_assign_value_to_variable\u001b[1;34m(variable, value)\u001b[0m\n\u001b[0;32m   4356\u001b[0m     variable\u001b[38;5;241m.\u001b[39massign(d_value)\n\u001b[0;32m   4357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4358\u001b[0m     \u001b[38;5;66;03m# For the normal tf.Variable assign\u001b[39;00m\n\u001b[1;32m-> 4359\u001b[0m     variable\u001b[38;5;241m.\u001b[39massign(value)\n",
      "File \u001b[1;32mc:\\Users\\crpdn\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32mc:\\Users\\crpdn\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1056\u001b[0m, in \u001b[0;36mBaseResourceVariable.assign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m   1054\u001b[0m   validate_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_shape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape\u001b[38;5;241m.\u001b[39mis_fully_defined()\n\u001b[0;32m   1055\u001b[0m   kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m validate_shape\n\u001b[1;32m-> 1056\u001b[0m assign_op \u001b[38;5;241m=\u001b[39m gen_resource_variable_ops\u001b[38;5;241m.\u001b[39massign_variable_op(\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, value_tensor, name\u001b[38;5;241m=\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_value:\n\u001b[0;32m   1059\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_read(assign_op)\n",
      "File \u001b[1;32mc:\\Users\\crpdn\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:149\u001b[0m, in \u001b[0;36massign_variable_op\u001b[1;34m(resource, value, validate_shape, name)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    148\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m    150\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssignVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, resource, value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    151\u001b[0m       validate_shape)\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    153\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = df[ ['Pattern','Time','Ch4(mA)','On time', 'Off time']]\n",
    "df = df.rename(columns={'Ch4(mA)': 'Current'})\n",
    "df_original = df.drop(df.index[:50*10])\n",
    "\n",
    "for i in  range(10):#range(int(df.shape[0]/50)):\n",
    "    data = df_original.iloc[i*50:(i+1)*50]\n",
    "\n",
    "    x_time = data['Time']-np.min(data['Time'])\n",
    "    y_current = data['Current']\n",
    "    points = len(y_current) \n",
    "    X_data = np.zeros((1,3))\n",
    "    #initialize array of expected shape\n",
    "    y_data = np.zeros((1, points, 2))\n",
    "    \n",
    "    label = np.column_stack((x_time,y_current))  \n",
    "    y_data[0,:,:]= label\n",
    "    features =  np.array([np.min(y_current.values), data['On time'].iloc[0], data['Off time'].iloc[0]])\n",
    "    X_data[0,:] = features\n",
    "\n",
    "    X_train = X_data\n",
    "    y_train = y_data\n",
    "\n",
    "    if load:\n",
    "        model = keras.models.load_model(model_path, custom_objects={'custom_loss':custom_loss})\n",
    "    else:\n",
    "        model = create_nn()\n",
    "\n",
    "    compile_model(model)\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=number_of_epochs,\n",
    "                    # validation_data = (X_val,y_val),\n",
    "                    callbacks=[earlystopper\n",
    "                               ,reduce_lr\n",
    "                               ],\n",
    "                    verbose=0)\n",
    "    history_df = pd.DataFrame.from_dict(history.history)\n",
    "    final_loss = history_df['loss'].iloc[-1]\n",
    "    if final_loss < 0.1:\n",
    "        y_train_prediction = model.predict(X_train)\n",
    "        param_predicted = y_train_prediction[0,0 ,: ]\n",
    "        predicted_param_list.append(param_predicted)\n",
    "        # print(param_predicted)\n",
    "    \n",
    "    else:\n",
    "\n",
    "        not_completed.append(i)\n",
    "        predicted_param_list.append(np.zeros_like(param_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 9]\n",
      "[array([0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0.], dtype=float32), array([23.410318  ,  0.13154048, 33.543915  , 33.82794   ,  0.84700984],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(not_completed)\n",
    "print(predicted_param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predicted_param_list)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('outputs/parameters1.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
