{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def getParameters(x):\n",
    "\n",
    "    #since x comes in as a batch with shape (20,4) -- (or any other batch size different from 20)\n",
    "\n",
    "    #let's condense X in one sample only, because we want only 4 elements, not 20*4 elements\n",
    "    xCondensed = K.mean(x,axis=0,keepdims=True)\n",
    "        #I'm using keepdims because we will need that x end up with the same number of samples for compatibility purposes (keras rules)\n",
    "\n",
    "    #let's expand x again (for compatibility purposes), now repeating the 4 values 20 (or more) times\n",
    "    #return K.ones_like(x) * xCondensed\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def yourFunction(x):\n",
    "\n",
    "\n",
    "    #now x has 4 parameters (assuming you had a Dense(4) before these lambda layers)\n",
    "    A1 = x[:,0]\n",
    "    b = x[:,1]\n",
    "    c = x[:,2]\n",
    "    d = x[:,3]\n",
    "\n",
    "    #creating the 20 (or more) iterations\n",
    "    ones = K.ones((20,1))\n",
    "    iterationsStartingAt1= K.cumsum(ones)\n",
    "    iterationsStartingAt0= iterationsStartingAt1 - 1\n",
    "    iterations = iterationsStartingAt0\n",
    "\n",
    "    return A1*np.exp(-(t+toff1)/t1)+A2*np.exp(-(t+toff2)/t2)+j0\n",
    "    return (a * K.sin((b*iterations) + c)) + d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cierpind\\Desktop\\Coding\\Machine_Learning\\keras_neural.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cierpind/Desktop/Coding/Machine_Learning/keras_neural.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cierpind/Desktop/Coding/Machine_Learning/keras_neural.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m#print(model.summary())\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cierpind/Desktop/Coding/Machine_Learning/keras_neural.ipynb#W1sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m plot_model(model, to_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel_plot.png\u001b[39m\u001b[39m'\u001b[39m, show_shapes\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, show_layer_names\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\cierpind\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\vis_utils.py:445\u001b[0m, in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations, show_trainable)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Converts a Keras model to dot format and save to a file.\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \n\u001b[0;32m    394\u001b[0m \u001b[39mExample:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[39m  This enables in-line display of the model plots in notebooks.\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m--> 445\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    446\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis model has not yet been built. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    447\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe model on a batch of data.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m     )\n\u001b[0;32m    451\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m check_graphviz():\n\u001b[0;32m    452\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[0;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou must install pydot (`pip install pydot`) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand install graphviz \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    455\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(see instructions at https://graphviz.gitlab.io/download/) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfor plot_model to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "#commentary to this specific problem found here:\n",
    "#https://stackoverflow.com/questions/46227823/keras-neural-network-outputting-function-parameters-how-to-construct-loss-func\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "inputs_parameters = tf.keras.Input(shape=(300,))\n",
    "inputs_second_half = tf.keras.Input(shape=(200,))\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add input layer\n",
    "model.add(Dense(units=input_size, activation='relu', input_dim=input_size))\n",
    "\n",
    "# Add hidden layers (you can customize the number of layers and units)\n",
    "num_hidden_layers = 2\n",
    "for _ in range(num_hidden_layers):\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(units=output_size, activation='linear'))\n",
    "\n",
    "#model.add(Lambda(getParameters,output_shape=(4,),name='paramLayer'))\n",
    "#model.add(Lambda(yourFunction,output_shape=(1,),name='valueLayer'))\n",
    "\n",
    "# Compile the model with the custom loss function\n",
    "model.compile(optimizer='adam')\n",
    "\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
